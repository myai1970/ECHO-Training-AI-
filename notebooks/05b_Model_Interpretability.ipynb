{"cells":[{"cell_type":"markdown","metadata":{"id":"AxUxA4iKRLVk"},"source":["# Model Interpretability with SHAP\n","\n","**DOST-ITDI AI Training Workshop**  \n","**Day 2 - Session 5: Understanding Model Predictions**\n","\n","---\n","\n","## Learning Objectives\n","1. Understand why model interpretability matters\n","2. Learn SHAP (SHapley Additive exPlanations) fundamentals\n","3. Interpret predictions from regression models\n","4. Interpret predictions from classification models\n","5. Apply interpretability to chemistry problems\n","6. Make better decisions using model insights\n","\n","## Why Model Interpretability?\n","\n","### The Black Box Problem\n","Machine learning models can make accurate predictions, but often we don't understand **why**.\n","\n","**Questions we want to answer:**\n","- Which features are most important?\n","- Why did the model predict this value?\n","- Can we trust this prediction?\n","- What happens if we change a feature?\n","\n","### Why This Matters in Science\n","- **Regulatory compliance** - FDA, EPA need explanations\n","- **Scientific discovery** - Find new insights\n","- **Trust** - Convince stakeholders\n","- **Debugging** - Find model errors\n","- **Ethical AI** - Detect bias\n","\n","### Example: Drug Development\n","Model says: \"This compound will be 85% bioavailable\"\n","\n","**We need to know:**\n","- Which molecular features drove this prediction?\n","- Is the model focusing on the right chemistry?\n","- Should we trust this for a $10M clinical trial decision?"]},{"cell_type":"markdown","metadata":{"id":"K4VjRK9WRLVn"},"source":["## Section 1: Setup and Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3WvCGSs5RLVo"},"outputs":[],"source":["# Install SHAP\n","!pip install shap scikit-learn rdkit xgboost -q\n","\n","print(\"[OK] Libraries installed!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14b7lbTPRLVq"},"outputs":[],"source":["# Import libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import shap\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Machine learning\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n","import xgboost as xgb\n","\n","# Chemistry\n","from rdkit import Chem\n","from rdkit.Chem import Descriptors\n","\n","# Set style\n","sns.set_style('whitegrid')\n","plt.rcParams['figure.figsize'] = (12, 6)\n","np.random.seed(42)\n","\n","print(\"[OK] Libraries imported!\")"]},{"cell_type":"markdown","metadata":{"id":"p9HG_m_7RLVr"},"source":["### 1.1 Load ESOL Dataset (Solubility Prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cYThp9jRLVs"},"outputs":[],"source":["# Load ESOL dataset - same as notebooks 01, 02, 04!\n","url = \"https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/delaney-processed.csv\"\n","df = pd.read_csv(url)\n","\n","print(f\"Loaded {len(df)} molecules\")\n","print(f\"\\nColumns: {df.columns.tolist()}\")\n","print(f\"\\nFirst few rows:\")\n","display(df.head())\n","\n","# Target: measured log solubility\n","print(f\"\\nTarget variable: measured log solubility in mols per litre\")\n","print(f\"Range: [{df['measured log solubility in mols per litre'].min():.2f}, {df['measured log solubility in mols per litre'].max():.2f}]\")"]},{"cell_type":"markdown","metadata":{"id":"oeQLKl8mRLVt"},"source":["### 1.2 Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNvf5w3SRLVu"},"outputs":[],"source":["# Calculate molecular descriptors using RDKit\n","def calculate_descriptors(smiles):\n","    \"\"\"Calculate molecular descriptors from SMILES\"\"\"\n","    mol = Chem.MolFromSmiles(smiles)\n","    if mol is None:\n","        return None\n","\n","    return {\n","        'MolWt': Descriptors.MolWt(mol),\n","        'LogP': Descriptors.MolLogP(mol),\n","        'NumHDonors': Descriptors.NumHDonors(mol),\n","        'NumHAcceptors': Descriptors.NumHAcceptors(mol),\n","        'NumRotatableBonds': Descriptors.NumRotatableBonds(mol),\n","        'NumAromaticRings': Descriptors.NumAromaticRings(mol),\n","        'TPSA': Descriptors.TPSA(mol),\n","        'NumAtoms': mol.GetNumAtoms()\n","    }\n","\n","# Calculate for all molecules\n","print(\"Calculating molecular descriptors...\")\n","descriptors = []\n","for smiles in df['smiles']:\n","    desc = calculate_descriptors(smiles)\n","    descriptors.append(desc)\n","\n","# Create features DataFrame\n","features_df = pd.DataFrame(descriptors)\n","features_df['Compound'] = df['Compound ID'].values\n","features_df['Solubility'] = df['measured log solubility in mols per litre'].values\n","\n","# Remove any failed conversions\n","features_df = features_df.dropna()\n","\n","print(f\"\\n[OK] Calculated descriptors for {len(features_df)} molecules\")\n","print(f\"\\nFeatures: {features_df.columns.tolist()[:-2]}\")\n","display(features_df.head())"]},{"cell_type":"markdown","metadata":{"id":"-xqM4VTGRLVw"},"source":["## Section 2: Train Regression Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xopb-7iPRLVy"},"outputs":[],"source":["# Prepare data\n","feature_cols = ['MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors',\n","                'NumRotatableBonds', 'NumAromaticRings', 'TPSA', 'NumAtoms']\n","\n","X = features_df[feature_cols]\n","y = features_df['Solubility']\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","print(f\"Training set: {X_train.shape[0]} molecules\")\n","print(f\"Test set: {X_test.shape[0]} molecules\")\n","\n","# Train Random Forest\n","print(\"\\nTraining Random Forest model...\")\n","rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predictions\n","y_pred = rf_model.predict(X_test)\n","\n","# Evaluate\n","r2 = r2_score(y_test, y_pred)\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","print(f\"\\n[OK] Model trained!\")\n","print(f\"R² Score: {r2:.4f}\")\n","print(f\"RMSE: {rmse:.4f}\")\n","\n","# Visualize predictions\n","plt.figure(figsize=(8, 6))\n","plt.scatter(y_test, y_pred, alpha=0.6, edgecolors='k')\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n","plt.xlabel('Actual Solubility', fontsize=12)\n","plt.ylabel('Predicted Solubility', fontsize=12)\n","plt.title(f'Model Performance (R² = {r2:.4f})', fontsize=14, fontweight='bold')\n","plt.grid(True, alpha=0.3)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"BRPU-4alRLV0"},"source":["## Section 3: SHAP - Understanding the Basics\n","\n","### What is SHAP?\n","\n","**SHAP** = SHapley Additive exPlanations\n","\n","Based on game theory (Shapley values) - fairly distributes \"credit\" for a prediction among features.\n","\n","### Key Concepts:\n","\n","1. **SHAP Value** = How much a feature contributes to a prediction\n","   - Positive SHAP → increases prediction\n","   - Negative SHAP → decreases prediction\n","   - Zero SHAP → no effect\n","\n","2. **Base Value** = Average prediction across all data\n","\n","3. **Prediction** = Base Value + sum of all SHAP values\n","\n","### Analogy: Team Project Grade\n","\n","Your team got 85/100 on a project. How much did each member contribute?\n","\n","- **Base value**: Average grade = 75\n","- **Alice**: +8 (excellent research)\n","- **Bob**: +5 (good presentation)\n","- **Carlos**: -3 (late submission)\n","- **Diana**: 0 (average contribution)\n","\n","**Final**: 75 + 8 + 5 - 3 + 0 = **85**\n","\n","SHAP does this for features!"]},{"cell_type":"markdown","metadata":{"id":"1cN11mfFRLV1"},"source":["### 3.1 Initialize SHAP Explainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEjPZJAlRLV2"},"outputs":[],"source":["# Create SHAP explainer for Random Forest\n","print(\"Creating SHAP explainer...\")\n","explainer = shap.TreeExplainer(rf_model)\n","\n","# Calculate SHAP values for test set\n","print(\"Calculating SHAP values (this may take a minute)...\")\n","shap_values = explainer.shap_values(X_test)\n","\n","print(f\"\\n[OK] SHAP values calculated!\")\n","print(f\"Shape: {shap_values.shape}\")\n","print(f\"  - {shap_values.shape[0]} test samples\")\n","print(f\"  - {shap_values.shape[1]} features\")\n","\n","# Base value (average prediction)\n","base_value = explainer.expected_value\n","print(f\"\\nBase value (average prediction): {base_value:.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"ryl_GkfPRLV3"},"source":["### 3.2 Global Feature Importance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24zYhL5_RLV3"},"outputs":[],"source":["# Summary plot - shows overall feature importance\n","print(\"Feature Importance (Global View)\")\n","print(\"=\"*60)\n","\n","shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\n[INFO] This shows which features are most important OVERALL\")\n","print(\"Higher bar = more impact on predictions across all molecules\")"]},{"cell_type":"markdown","metadata":{"id":"5jPG0XJvRLV4"},"source":["### 3.3 Summary Plot - Feature Effects"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"prmbinhiRLV4"},"outputs":[],"source":["# Summary plot - shows how features affect predictions\n","print(\"Feature Effects Summary\")\n","print(\"=\"*60)\n","print(\"How to read this plot:\")\n","print(\"  - Each dot = one molecule\")\n","print(\"  - X-axis: SHAP value (impact on prediction)\")\n","print(\"  - Color: Feature value (red=high, blue=low)\")\n","print(\"\\nExample: If LogP has red dots on the right:\")\n","print(\"  -> High LogP increases solubility prediction\")\n","print(\"=\"*60)\n","\n","shap.summary_plot(shap_values, X_test)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"OzctOCMERLV4"},"source":["## Section 4: Individual Predictions\n","\n","### 4.1 Explain a Single Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfHc0bn3RLV5"},"outputs":[],"source":["# Pick a molecule to explain\n","sample_idx = 0\n","sample = X_test.iloc[sample_idx]\n","actual_value = y_test.iloc[sample_idx]\n","predicted_value = rf_model.predict([sample])[0]\n","\n","print(\"Explaining Individual Prediction\")\n","print(\"=\"*60)\n","print(f\"Molecule #{sample_idx}\")\n","print(f\"\\nActual Solubility: {actual_value:.4f}\")\n","print(f\"Predicted Solubility: {predicted_value:.4f}\")\n","print(f\"Base Value (average): {base_value:.4f}\")\n","print(f\"\\nMolecular Features:\")\n","for feat, val in sample.items():\n","    print(f\"  {feat:20}: {val:.2f}\")\n","print(\"=\"*60)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbJLiix1RLV6"},"outputs":[],"source":["# Waterfall plot - shows how we get from base value to prediction\n","print(\"\\nWaterfall Plot - How Features Build the Prediction\")\n","print(\"=\"*60)\n","print(\"This shows step-by-step how each feature contributes:\")\n","print(\"  - Start at base value (average)\")\n","print(\"  - Each bar adds or subtracts from prediction\")\n","print(\"  - End at final predicted value\")\n","print(\"=\"*60)\n","\n","shap.plots.waterfall(shap.Explanation(\n","    values=shap_values[sample_idx],\n","    base_values=base_value,\n","    data=sample,\n","    feature_names=feature_cols\n","))\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3eBIdAJRLV6"},"outputs":[],"source":["# Force plot - another way to visualize individual prediction\n","print(\"\\nForce Plot - Visual Breakdown\")\n","print(\"=\"*60)\n","print(\"Red features = push prediction HIGHER\")\n","print(\"Blue features = push prediction LOWER\")\n","print(\"Width = magnitude of effect\")\n","print(\"=\"*60)\n","\n","shap.initjs()\n","shap.force_plot(\n","    base_value,\n","    shap_values[sample_idx],\n","    sample,\n","    matplotlib=True\n",")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9xnQcDydRLV7"},"source":["### 4.2 Compare Multiple Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSPlkWJrRLV7"},"outputs":[],"source":["# Compare 3 molecules\n","indices = [0, 10, 20]\n","\n","fig, axes = plt.subplots(len(indices), 1, figsize=(12, 4*len(indices)))\n","\n","for i, idx in enumerate(indices):\n","    sample = X_test.iloc[idx]\n","    actual = y_test.iloc[idx]\n","    pred = rf_model.predict([sample])[0]\n","\n","    # Create waterfall data\n","    shap_exp = shap.Explanation(\n","        values=shap_values[idx],\n","        base_values=base_value,\n","        data=sample,\n","        feature_names=feature_cols\n","    )\n","\n","    plt.sca(axes[i])\n","    shap.plots.waterfall(shap_exp, show=False)\n","    axes[i].set_title(f'Molecule #{idx} | Actual: {actual:.3f}, Predicted: {pred:.3f}',\n","                      fontweight='bold')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\n[INFO] Notice how different features drive predictions for different molecules!\")"]},{"cell_type":"markdown","metadata":{"id":"G2xTKkLiRLV7"},"source":["## Section 5: Feature Dependence\n","\n","### 5.1 How does LogP affect predictions?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TD_ygj9bRLV8"},"outputs":[],"source":["# Dependence plot - shows relationship between feature value and SHAP value\n","print(\"Feature Dependence: LogP\")\n","print(\"=\"*60)\n","print(\"This shows how LogP affects predictions:\")\n","print(\"  - X-axis: LogP value\")\n","print(\"  - Y-axis: SHAP value (impact on prediction)\")\n","print(\"  - Color: Another feature (interaction effect)\")\n","print(\"=\"*60)\n","\n","shap.dependence_plot(\n","    \"LogP\",\n","    shap_values,\n","    X_test,\n","    interaction_index=\"MolWt\"\n",")\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\n[KEY INSIGHT]\")\n","print(\"If the plot shows an upward trend:\")\n","print(\"  -> Higher LogP leads to higher predicted solubility\")\n","print(\"If there's a color gradient:\")\n","print(\"  -> The effect of LogP depends on MolWt (interaction)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CftpA3tVRLV8"},"outputs":[],"source":["# Multiple dependence plots\n","important_features = ['LogP', 'MolWt', 'TPSA', 'NumAromaticRings']\n","\n","fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n","axes = axes.ravel()\n","\n","for i, feat in enumerate(important_features):\n","    plt.sca(axes[i])\n","    shap.dependence_plot(\n","        feat,\n","        shap_values,\n","        X_test,\n","        show=False\n","    )\n","    axes[i].set_title(f'Effect of {feat}', fontweight='bold', fontsize=12)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"vhhtlGpiRLV9"},"source":["## Section 6: Decision Plot - Multiple Molecules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJmHi5GXRLV9"},"outputs":[],"source":["# Decision plot - shows prediction paths for multiple molecules\n","print(\"Decision Plot - Prediction Paths\")\n","print(\"=\"*60)\n","print(\"This shows how predictions are built step by step:\")\n","print(\"  - Each line = one molecule\")\n","print(\"  - Start at base value (left)\")\n","print(\"  - Each feature shifts the line up or down\")\n","print(\"  - End at predicted value (right)\")\n","print(\"=\"*60)\n","\n","# Select a subset of molecules\n","subset_idx = np.random.choice(len(X_test), 20, replace=False)\n","\n","shap.decision_plot(\n","    base_value,\n","    shap_values[subset_idx],\n","    X_test.iloc[subset_idx],\n","    feature_names=feature_cols\n",")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"E46e_N34RLV-"},"source":["## Section 7: Practical Applications\n","\n","### 7.1 Find Unusual Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wdoxMuqRLV-"},"outputs":[],"source":["# Find molecules with large prediction errors\n","errors = np.abs(y_test.values - y_pred)\n","worst_idx = np.argmax(errors)\n","\n","print(\"Analyzing Worst Prediction\")\n","print(\"=\"*60)\n","print(f\"Molecule index: {worst_idx}\")\n","print(f\"Actual: {y_test.iloc[worst_idx]:.4f}\")\n","print(f\"Predicted: {y_pred[worst_idx]:.4f}\")\n","print(f\"Error: {errors[worst_idx]:.4f}\")\n","print(\"\\nWhy did the model get this wrong?\")\n","print(\"=\"*60)\n","\n","# Explain this prediction\n","sample = X_test.iloc[worst_idx]\n","shap.plots.waterfall(shap.Explanation(\n","    values=shap_values[worst_idx],\n","    base_values=base_value,\n","    data=sample,\n","    feature_names=feature_cols\n","))\n","plt.title(f'Worst Prediction Analysis (Error: {errors[worst_idx]:.4f})',\n","          fontweight='bold')\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\n[INSIGHT] This helps us understand model limitations!\")\n","print(\"Maybe the model needs more features, or this molecule is an outlier.\")"]},{"cell_type":"markdown","metadata":{"id":"22P2TyLGRLV-"},"source":["### 7.2 Feature Engineering Insights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sjT-AR7RLV_"},"outputs":[],"source":["# Calculate average absolute SHAP values for each feature\n","mean_abs_shap = np.abs(shap_values).mean(axis=0)\n","\n","feature_importance = pd.DataFrame({\n","    'Feature': feature_cols,\n","    'Importance': mean_abs_shap\n","}).sort_values('Importance', ascending=False)\n","\n","print(\"Feature Importance Ranking\")\n","print(\"=\"*60)\n","print(feature_importance.to_string(index=False))\n","print(\"=\"*60)\n","\n","# Visualize\n","plt.figure(figsize=(10, 6))\n","plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\n","plt.xlabel('Mean |SHAP Value|', fontsize=12)\n","plt.title('Feature Importance for Solubility Prediction', fontsize=14, fontweight='bold')\n","plt.gca().invert_yaxis()\n","plt.grid(axis='x', alpha=0.3)\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\n[RECOMMENDATION]\")\n","print(f\"Top 3 features: {', '.join(feature_importance['Feature'].head(3).tolist())}\")\n","print(\"Focus on these when designing new molecules!\")\n","print(f\"\\nLeast important: {feature_importance['Feature'].iloc[-1]}\")\n","print(\"Consider removing or replacing with better features.\")"]},{"cell_type":"markdown","metadata":{"id":"xHtgCWd8RLWA"},"source":["## Section 8: Summary & Best Practices\n","\n","### What We Learned:\n","\n","1. **SHAP Values**\n","   - Explain how features contribute to predictions\n","   - Based on solid game theory (Shapley values)\n","   - Works for any model (trees, neural networks, etc.)\n","\n","2. **Global Interpretation**\n","   - Summary plots show overall feature importance\n","   - Dependence plots show feature effects\n","   - Helps understand model behavior\n","\n","3. **Local Interpretation**\n","   - Waterfall plots explain individual predictions\n","   - Force plots show feature contributions visually\n","   - Builds trust in specific decisions\n","\n","4. **Practical Applications**\n","   - Debug bad predictions\n","   - Identify important features\n","   - Guide feature engineering\n","   - Discover new insights\n","\n","### Best Practices:\n","\n","1. **Always Interpret Important Decisions**\n","   - High-stakes predictions (drug approval, safety)\n","   - Unexpected results\n","   - Regulatory requirements\n","\n","2. **Check for Sensibility**\n","   - Do the important features make scientific sense?\n","   - Are there spurious correlations?\n","   - Is the model learning the right chemistry?\n","\n","3. **Use Multiple Views**\n","   - Global: Summary plots, feature importance\n","   - Local: Waterfall, force plots\n","   - Dependence: How features interact\n","\n","4. **Combine with Domain Knowledge**\n","   - SHAP shows correlations, not causation\n","   - Validate insights with chemistry knowledge\n","   - Use to generate hypotheses, then test experimentally\n","\n","### When to Use SHAP:\n","\n","✅ **Good for:**\n","- Understanding model predictions\n","- Debugging models\n","- Building trust with stakeholders\n","- Feature selection\n","- Scientific discovery\n","\n","❌ **Not sufficient for:**\n","- Proving causation (use experiments)\n","- Replacing domain expertise\n","- Legal compliance alone (consult regulations)\n","\n","### Connection to Other Notebooks:\n","\n","| Notebook | Connection |\n","|----------|------------|\n","| **02_Regression** | Applied SHAP to regression models |\n","| **03_Classification** | Can apply same techniques to classifiers |\n","| **04_PyTorch** | SHAP works with neural networks too |\n","| **06_CV** | Next: Visualize what CNNs learn |\n","\n","### Resources:\n","\n","- [SHAP Documentation](https://shap.readthedocs.io/)\n","- [Interpretable ML Book](https://christophm.github.io/interpretable-ml-book/)\n","- [SHAP Paper](https://arxiv.org/abs/1705.07874)\n","\n","---\n","\n","**Key Takeaway**: A model you can explain is a model you can trust and improve!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[{"file_id":"https://github.com/jomaminoza/dost-ai-training/blob/main/notebooks/05b_Model_Interpretability.ipynb","timestamp":1764397211264}]}},"nbformat":4,"nbformat_minor":0}